# -*- coding: utf-8 -*-
"""Predictive_Analytics_Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qg69pEclxIkiWY4vdJYz-W6qYJyf0-ON

# Import Library
"""

# Untuk manipulasi dan analisis data
import pandas as pd

# Untuk visualisasi data
import matplotlib.pyplot as plt
import seaborn as sns

# Untuk modeling, preprocessing, dan evaluasi
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error

import warnings
warnings.filterwarnings('ignore', category=UserWarning)

"""# Load Dataset"""

from google.colab import userdata
import os

os.environ["KAGGLE_KEY"] = userdata.get('KAGGLE_KEY')
os.environ["KAGGLE_USERNAME"] = userdata.get('KAGGLE_USERNAME')

!kaggle datasets download -d muhammadbinimran/housing-price-prediction-data
! unzip 'housing-price-prediction-data.zip'

house = pd.read_csv('housing_price_dataset.csv')

house

"""Insight:

- Terdapat 50.000 baris dalam dataset.
- Terdapat 6 kolom dalam dataset yang mencakup: SquareFeet, Bedrooms, Bathrooms, Neighborhood, YearBuilt, dan Price

# Exploratory Data Analysis

## Variable Description
"""

house.info()

house['Neighborhood'].unique()

"""Insight:
- Terdapat 1 kolom dengan tipe object, yakni Neighborhood. Kolom ini merupakan fitur non-numerik, sehingga nantinya akan dilakukan konversi ke numerik untuk kebutuhan analisis.
- Terdapat 4 kolom dengan tipe int64, yakni SquareFeet, Bedrooms, Bathrooms, dan YearBuilt. Seluruh kolom ini merupakan fitur numerik.
- Terdapat 1 kolom dengan tipe float64, yakni Price. Kolom ini juga merupakan fitur numerik.
- SquareFeet merepresentasikan luas bangunan rumah dalam satuan kaki persegi (ukuran total area)
- Bedrooms merepresentasikan jumlah kamar tidur yang tersedia di setiap rumah.
- Bathrooms merepresentasikan jumlah kamar mandi yang tersedia di setiap rumah.
- Neighborhood merepresentasikan area lingkungan dari setiap rumah dengan  3 pilihan utama berupa Rural, Suburb, Urban.
- YearBuilt merepresentasikan tahun di mana setiap rumah dibangun.
- Price merupakan fitur target, yang merepresentasikan harga dari sebuah rumah.
"""

house.describe()

"""Insight:
- Jumlah sampel pada seluruh kolom numerik terdiri dari 50.000 sampel.
- Diketahui bahwa rata-rata luas bangunan rumah adalah 2006,37 kaki persegi, dengan rentang ukuran mulai dari 1000 hingga 2999 kaki persegi. Persebarannya cukup besar yang dapat menunjukkan bahwa ukuran rumah bervariasi antarsampel.
- Diketahui bahwa rumah dalam dataset ini memiliki rata-rata 3 kamar tidur, dengan jumlah minimum 2 kamar dan maksimum 5 kamar. Persebarannya kecil, yang menandakan persebaran relatif konsisten.
- Diketahui bahwa rata-rata rumah memiliki 1 kamar mandi, dengan jumlah maksimum 3 kamar mandi. Persebarannya juga rendah, yang mengindikasikan bahwa sebagian besar rumah memiliki jumlah kamar mandi yang hampir sama.
- Diketahui bahwa rumah-rumah dalam dataset ini rata-rata dibangun pada tahun 1985, dengan tahun pembangunan tertua 1950 dan terbaru 2021. Persebarannya tidak terlalu tinggi dan tidak terlalu rendah (sedang), yang menandakan bahwa tahun pembangunan rumah beragam tapi tidak ekstrem.
- Diketahui bahwa harga rata-rata rumah tersebut adalah 224.827,32, dengan harga termurah sebesar -36.588,16 dan harga tertinggi 492.195,25. Nilai harga yang negatif menunjukkan adanya anomali data atau kesalahan input yang perlu diperiksa lebih lanjut. Persebarannya terlihat cukup besar, yang dapat menandakan bahwa harga rumah bervariasi.

## Missing Values
"""

house.isna().sum()

"""Insight:

Dataset tidak mengandung nilai kosong.

## Outlier Detection and Handling

**Memeriksa Outlier**
"""

sns.boxplot(x=house['SquareFeet'])
plt.show()

sns.boxplot(x=house['Bedrooms'])
plt.show()

sns.boxplot(x=house['Bathrooms'])
plt.show()

sns.boxplot(x=house['YearBuilt'])
plt.show()

sns.boxplot(x=house['Price'])
plt.show()

"""Insight:
- Hasil visualisasi menggunakan boxplot pada seluruh fitur numerik menunjukkan bahwa outliers hanya ditemukan pada fitur Price, sehingga perlu dilakukan penanganan pada fitur tersebut.

## Univariate Analysis
"""

# Membagi fitur sesuai dengan karakteristik
numerical_features = ['SquareFeet', 'Bedrooms', 'Bathrooms', 'YearBuilt', 'Price']
categorical_features = ['Neighborhood']

"""**Fitur Numerik**"""

house.hist(bins=50, figsize=(16, 9))
plt.show()

"""- Distribusi SquareFeet merata dari 1000 hingga 3000, dan tidak ada ukuran yang mendominasi secara signifikan.
- Bedrooms hanya mencakup 2, 3, 4, dan 5 kamar tidur. Distribusinya seimbang, tetapi 3 kamar lebih mendominasi.
- Bathrooms hanya mencakup 1, 2, dan 3 kamar mandi. Distribusinya cukup seimbang.
- Distribusi harga rumah tampak normal dengan puncak yang berada di sekitar 200.000 - 250.000. Terdapat sedikit kemiringan ke kanan (positive skew), yang menunjukkan bahwa sebagian kecil rumah berharga jauh lebih mahal.
- DiDistribusi tahun pembangunan rumah menunjukkan pola yang relatif stabil dan seimbang di setiap dekade, dengan sedikit fluktuasi periodik.

**Fitur Category**
"""

feature = categorical_features[0]
count = house[feature].value_counts()
percent = 100 * house[feature].value_counts(normalize=True)

df = pd.DataFrame({'Jumlah Sampel':count, 'Persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature)
plt.show()

"""Insight:
- Distribusi seluruh kategori dalam fitur Neighborhood menunjukkan pola yang hampir seragam, dengan jumlah sampel yang relatif merata di setiap kategori.

## Multivariate Analysis
"""

sns.catplot(x='Neighborhood', y='Price', kind='bar', dodge=False, height = 5, aspect = 3, data = house, color='royalblue')
plt.title(f'Rata-rata Price Relatif terhadap Neighborhood')
plt.show()

"""Insight:
- Berdasarkan visualisasi, rata-rata harga rumah di setiap kategori Neighborhood (Rural, Suburb, Urban) terlihat relatif setara. Hal ini menunjukkan bahwa variabel Neighborhood mungkin tidak memiliki pengaruh yang signifikan terhadap Price.
"""

sns.pairplot(house, diag_kind='kde')
plt.show()

"""Insight:
- Price dan SquareFeet terlihat memiliki hubungan positif yang kuat, di mana semakin besar luas bangunan semakin tinggi pula harganya. Ini dapat mengindikasikan bahwa luas bangunan adalah salah satu prediktor yang kuat.
- Price dan Bedrooms terlihat tidak memiliki korelasi yang kuat.
- Price dan Bathrooms terlihat tidak memiliki korelasi yang kuat juga.
- Price dan YearBuilt terlihat memiliki pola acak, yang dapat mengindikasikan bahwa keduanya tidak memiliki pola korelasi yang jelas.
"""

plt.figure(figsize=(16, 8))

corr_matrix = house[numerical_features].corr().round(2)
sns.heatmap(data=corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix untuk Fitur Numerik', size=14)
plt.show()

"""Insight:
- Price dan SquareFeet memiliki korelasi yang cukup kuat, yakni sebesar 0,75.
- Price dan Bedrooms memiliki korelasi yang lemah mendekati 0, yaitu sebesar 0,07.
- Price dan Bathrooms memiliki korelasi yang sama lemahnya, mendekati 0, hanya sebesar 0,03.
- Price dan YearBuilt memiliki korelasi yang sangat kecil dan negatif hanya -0. Fitur ini dapat dipertimbangkan untuk dihapus.
- Tidak ada multikolinearitas yang signifikan sehingga PCA tidak perlu dilakukan.
"""

# Menghapus fitur Year
house.drop(['YearBuilt'], inplace=True, axis=1)
house.head()

"""# Data Preparation

### Menangani Outlier
"""

# Fungsi untuk menangani outlier dalam beberapa iterasi (2x)
def remove_outliers(df, column, max_iter=2):
  for i in range(max_iter):
    ## Menghitung Q1, Q3, dan IQR
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
  return df

# Menangani outlier pada dataset hourse
house = remove_outliers(house, 'Price')

# Menampilkan hasil dari pembersihan outliers
print(house.shape)
sns.boxplot(x=house['Price'])
plt.show()

"""Insight:

- Outlier pada fitur Price berhasil ditangani setelah dilakukan pembersihan dalam 2x iterasi dan jumlah sampel data berkurang dari 50.000 menjadi 49.940.

### Encoding Fitur Kategori
"""

# Encoding menggunakan One Hot Encoding
house = pd.concat([house, pd.get_dummies(house['Neighborhood'], prefix='Neighborhood')],axis=1)
house.drop(['Neighborhood'], axis=1, inplace=True)

house.head()

"""### Train-Test Split"""

X = house.drop(['Price'], axis=1)
y = house['Price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total number of sample in whole dataset: {len(X)}')
print(f'Total number of sample in train dataset: {len(X_train)}')
print(f'Total number of sample in test dataset: {len(X_test)}')

# Standarisasi terhadap Train dataset
numerical_features = ['SquareFeet', 'Bedrooms', 'Bathrooms']

scaler = StandardScaler()
scaler.fit(X_train[numerical_features])

X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""Insight:
- Setelah standarisasi, rata-rata nilai untuk fitur SquareFeet dan Bedrooms adalah -0, sedangkan Bathrooms 0.
- Setelah standarisasi, SquareFeet berada pada rentang -1,7483 hingga 1,7255, Bedrooms berada pada rentang -1,3409 hingga 1,3472, dan Bathroom berada pada rentang 1,2197 hingga 1,2308.

# Model Development

#### **Solution 1**
"""

# Inisialisasi model
lr_model = LinearRegression()
rf_model = RandomForestRegressor(n_estimators=60, random_state=42)
gb_model = GradientBoostingRegressor(random_state=42)

# Latih model dengan data training
lr_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)
gb_model.fit(X_train, y_train)

# Simpan dalam dictionary
models = {
    'LR': lr_model,
    'RF': rf_model,
    'GB': gb_model
}

"""#### **Solution 2**"""

# Random Forest with Randomized Search
rf = RandomForestRegressor(random_state=42)
rf_param = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [None, 5, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

rf_search = RandomizedSearchCV(rf, rf_param, cv=5, n_iter=10, random_state=42, n_jobs=-1)
rf_search.fit(X_train, y_train)
best_rf = rf_search.best_estimator_
print(best_rf)

# Gradient Boosting with Randomized Search
gb = GradientBoostingRegressor(random_state=42)
gb_param = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 10],
    'learning_rate': [0.01, 0.05, 0.1, 0.2]
}

gb_search = RandomizedSearchCV(gb, gb_param, cv=5, n_iter=10, random_state=42, n_jobs=-1)
gb_search.fit(X_train, y_train)
best_gb = gb_search.best_estimator_
print(best_gb)

# Simpan dalam dictionary
tuned_models = {
    'Tuned_RF': best_rf,
    'Tuned_GB': best_gb
}

"""Insight:
- Parameter yang dihasilkan oleh RandomizesSearch untuk model Random Forest mencakup `max_depth=5`, `min_samples_leaf=2`, `min_samples_split=10`, `n_estimators=50`, dan `random_state=42`.
- Parameter yang dihasilkan oleh RandomizedSearch untuk model Gradient Boosting mencakup `learning_rate=0.05`, `max_depth=5`, dan `random_state=42`

# Model Evaluation
"""

# Scaling terhadap fitur X_test
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

# Fungsi untuk evaluasi model
def evaluate_models(models, X_train, y_train, X_test, y_test):
  # Inisialisasi dataframe untuk menyimpan MSE
    mse = pd.DataFrame(columns=['train', 'test'], index=models.keys())

    for name, model in models.items():
        train_pred = model.predict(X_train)
        test_pred = model.predict(X_test)

        # Menghitung MSE
        mse.loc[name, 'train'] = mean_squared_error(y_train, train_pred) / 1e4
        mse.loc[name, 'test'] = mean_squared_error(y_test, test_pred) / 1e4

    return mse

"""#### **Solution 1**"""

# Melakukan evaluasi dan menampilkan hasil MSE untuk solusi 1
mse1 = evaluate_models(models, X_train, y_train, X_test, y_test)

mse1

# Menampilkan visualisasi hasil MSE untuk solusi 1
fig, ax = plt.subplots()
mse1.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Insight:
- Model Linear Regression (LR) memiliki selisih MSE yang kecil (~2.829), menunjukkan bahwa model ini memiliki performa yang konsisten antara data latih dan uji, meskipun tingkat kesalahan absolutnya lebih tinggi dibandingkan model lain.
- Model Random Forest (RF) menunjukkan selisih MSE yang sangat besar antara data latih dan data uji (~234.759). Hal ini mengindikasikan bahwa model overfitting, di mana performa model sangat baik pada data latih tetapi gagal melakukan generalisasi pada data uji.
- Model Gradient Boosting (GB) menunjukkan selisih MSE yang sangat kecil (~51), menjadikannya model dengan generalization paling stabil di antara ketiga model. Ini menandakan performa yang seimbang dan kuat di kedua dataset.

#### **Solution 2**
"""

# Melakukan evaluasi dan menampilkan hasil MSE untuk solusi 2
mse2 = evaluate_models(tuned_models, X_train, y_train, X_test, y_test)

mse2

# Menampilkan visualisasi hasil MSE untuk solusi 2
fig, ax = plt.subplots()
mse2.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Insight:
- Setelah melakukan penyesuaian pada paramaeter, model Random Forest (RF) menunjukkan selisih antara MSE latih dan uji yang sangat kecil (~662), yang mengindikasikan model ini sangat stabil dan memiliki generalisasi yang baik. Performa di data latih dan uji juga hampir identik, yang dapat diartikan bahwa model sudah tidak overfitting maupun underfitting.
- Setelah melakukan penyesuaian pada paramaeter, model Gradient Boosting (GB) menunjukkan selisih antara MSE latih dan uji yang sedikit lebih besar (~2.563).

## Prediction

#### **Solution 1**
"""

# Membandingkan hasil prediksi semua model dalam solusi 1
prediction = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in models.items():
    pred_dict['prediksi_'+name] = model.predict(prediction).round(1)

pd.DataFrame(pred_dict)

"""Insight:
- Linear Regression kurang tepat untuk kasus ini karena sangat jauh dari nilai aktual.
- Random Forest terlihat lebih baik dari Linear Regression, tetapi mengingat hasil evaluasinya mengindikasikan bahwa model ini overfitting menyebabkan keandalan prediksinya berkurang.
- Gradient Boosting memberikan prediksi yang paling akurat dan paling dekat dengan nilai aktual.

#### **Solution 2**
"""

# Membandingkan hasil prediksi semua model dalam solusi 2
prediction = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in tuned_models.items():
    pred_dict['prediksi_'+name] = model.predict(prediction).round(1)

pd.DataFrame(pred_dict)

"""Insight:
- Tuned Random Forest memberikan hasil prediksi yang paling dekat dengan nilai aktual, dengan selisih sekitar 2.525,6.
- Tuned Gradient Boosting juga memberikan prediksi yang cukup baik, meskipun masih terdapat selisih sekitar 6.874,1 dari nilai aktual.
"""